{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "#from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HISTORICO DE PARTIDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historico_partidas(tabela_url, paginas):\n",
    "  todas_partidas = []\n",
    "  data = requests.get(tabela_url) # Pega o html (em forma de string) da pagina 'Tabela do Brasileirao'\n",
    "  soup = BeautifulSoup(data.text) # Converte o String em html\n",
    "  tabela_brasileirao = soup.select('table.stats_table')[0] # Seleciona dentro do HTML a tabela em si\n",
    "  links_times = tabela_brasileirao.find_all('a') # Procura a Anchor que contem todos os links do time\n",
    "  links_times = [link.get(\"href\") for link in links_times] # Pega só os links em si\n",
    "  links_times = [link for link in links_times if paginas[0] in link] # Escolhe o link que leva para a pagina de Stats do time\n",
    "  times_urls = [f\"https://fbref.com{link}\" for link in links_times] # Transforma a string em URL\n",
    "\n",
    "  # Para cada time faça:\n",
    "  ## 1- Pega o nome do time\n",
    "  ## 2- Pega as informações das abas (em ordem):\n",
    "  ### Scores & Fixtures, Shooting, Goalkeeping, Passing, Pass Types, Goal and Shot Creation, Defensive Actions, Possession, Miscellaneous Stats\n",
    "  ## 3- Transforma a tabela que esta em HTML em Dataframe\n",
    "  for time_url in times_urls:\n",
    "    nome_time = time_url.split('/')[-1].replace(\"-Stats\", \"\")\n",
    "    data = requests.get(time_url) # Pega o html (em forma de string) da pagina do time\n",
    "    soup = BeautifulSoup(data.text)\n",
    "\n",
    "    ## Scores & Fixtures\n",
    "    partidas = pd.read_html(data.text, match= 'Scores & Fixtures')[0] # Transforma em dataframe o historico de partidas\n",
    "    \n",
    "    ## Shooting\n",
    "    links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "    links = [l for l in links if l and paginas[1] in l]\n",
    "    data_shooting = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "    shooting = pd.read_html(data_shooting.text, match= \"Shooting\")[0]\n",
    "    shooting.columns = shooting.columns.droplevel()\n",
    "    \n",
    "    ## Goalkeeping\n",
    "    links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "    links = [l for l in links if l and paginas[2] in l]\n",
    "    data_goalkeeping = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "    goalkeeping = pd.read_html(data_goalkeeping.text, match= \"Goalkeeping\")[0]\n",
    "    goalkeeping.columns = goalkeeping.columns.droplevel()\n",
    "    \n",
    "    ## Passing\n",
    "    links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "    links = [l for l in links if l and paginas[3] in l]\n",
    "    data_passing = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "    passing = pd.read_html(data_passing.text, match= \"Passing\")[0]\n",
    "    passing.columns = passing.columns.droplevel()\n",
    "    \n",
    "    ## Pass Types\n",
    "    links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "    links = [l for l in links if l and paginas[4] in l]\n",
    "    data_passtype = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "    pass_types = pd.read_html(data_passtype.text, match= \"Pass Types\")[0]\n",
    "    pass_types.columns = pass_types.columns.droplevel()\n",
    "    \n",
    "    ## Goal and Shot Creation\n",
    "    links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "    links = [l for l in links if l and paginas[5] in l]\n",
    "    data_shotcreation = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "    goal_shotcreation = pd.read_html(data_shotcreation.text, match= \"Goal and Shot Creation\")[0]\n",
    "    goal_shotcreation.columns = goal_shotcreation.columns.droplevel()\n",
    "    \n",
    "    ## Defensive Actions\n",
    "    links = [l.get(\"href\") for l in soup.find_all('a')]\n",
    "    links = [l for l in links if l and paginas[6] in l]\n",
    "    data_defensive = requests.get(f\"https://fbref.com{links[0]}\")\n",
    "    defensive = pd.read_html(data_defensive.text, match= \"Defensive Actions\")[0]\n",
    "    defensive.columns = defensive.columns.droplevel()\n",
    "    \n",
    "    ## Possession\n",
    "    ## Miscellaneous Stats\n",
    "\n",
    "    # Merge das abas\n",
    "    try:\n",
    "      time_df = partidas.merge(\n",
    "        shooting[['Date', 'Sh', 'SoT', 'SoT%', 'G/Sh', 'G/SoT', 'FK', 'PK', 'PKatt', 'npxG', 'npxG/Sh', 'G-xG', 'np:G-xG']], on= 'Date')\n",
    "      time_df = time_df.merge(\n",
    "        goalkeeping[['Date', 'SoTA', 'Saves', 'Save%', 'CS', 'PSxG', 'PSxG+/-']], on= 'Date')\n",
    "      time_df = time_df.merge(\n",
    "        passing[['Date', 'TotDist', 'PrgDist', 'Ast',\t'xAG', 'xA', 'KP', '1/3', 'PPA', 'CrsPA', 'PrgP']], on= 'Date') \n",
    "      time_df = time_df.merge(\n",
    "        pass_types[['Date', 'TB', 'Sw', 'Crs', 'Blocks']], on= 'Date')\n",
    "      time_df = time_df.merge(\n",
    "        goal_shotcreation[['Date', 'SCA', 'GCA']], on= 'Date')\n",
    "      time_df = time_df.merge(\n",
    "        defensive[['Date', 'TklW','Def 3rd','Mid 3rd','Att 3rd','Int','Err']], on= 'Date')\n",
    "      #time_df = time_df.merge(\n",
    "        #possession[['Date', ]], on= 'Date')\n",
    "      #time_df = time_df.merge(\n",
    "        #miscellaneous[['Date',]], on= 'Date')\n",
    "    except ValueError:\n",
    "      continue\n",
    "    \n",
    "    time_df = time_df[time_df[\"Comp\"] == \"Série A\"] # Filtra o brasileirão\n",
    "    time_df['Equipe'] = nome_time\n",
    "    todas_partidas.append(time_df)\n",
    "    time.sleep(10)\n",
    "\n",
    "  historico = pd.concat(todas_partidas)\n",
    "  return historico\n",
    "\n",
    "tabela = \"https://fbref.com/en/comps/24/Serie-A-Stats\"\n",
    "abas = ['/squads/', 'all_comps/shooting/', 'all_comps/keeper', 'all_comps/passing', 'all_comps/passing_types', 'all_comps/gca', 'all_comps/defense', 'all_comps/possession', 'all_comps/misc']\n",
    "historico = historico_partidas(tabela, abas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remover_acentos(texto):\n",
    "    return unidecode(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico.drop(\n",
    "  ['Notes','Captain', 'Formation', 'Referee', 'Match Report'], \n",
    "  axis= 'columns', inplace= True)\n",
    "historico[['GF', 'GA']] = historico[['GF', 'GA']].astype(int)\n",
    "historico['Opponent'] = historico['Opponent'].apply(remover_acentos)\n",
    "\n",
    "substitutions = {\n",
    "    'Botafogo-RJ': 'Botafogo (RJ)',\n",
    "    'Gremio': 'Gremio',\n",
    "    'Athletico-Paranaense': 'Ath Paranaense',\n",
    "    'Atletico-Mineiro': 'Atletico Mineiro',\n",
    "    'Sao-Paulo': 'Sao Paulo',\n",
    "    'Vasco-da-Gama': 'Vasco da Gama',\n",
    "    'America-MG': 'America (MG)'\n",
    "}\n",
    "\n",
    "for key, value in substitutions.items():\n",
    "    historico['Equipe'] = historico['Equipe'].str.replace(unidecode(key), value, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico_casa = historico[historico['Venue'] == 'Home']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar planilha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ultimo_jogo = historico['Date'].max()\n",
    "historico.to_excel(f'dados/historico/{data_ultimo_jogo}.xlsx', sheet_name='historico', index=False)\n",
    "historico_casa.to_excel(f'dados/historico/casa-{data_ultimo_jogo}.xlsx', sheet_name='historico', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabela_brasileirao(tabela_url):\n",
    "  data = requests.get(tabela_url)\n",
    "  tabela = pd.read_html(data.text, match= 'Regular season')[0]\n",
    "  return tabela\n",
    "\n",
    "tabela_url = \"https://fbref.com/en/comps/24/Serie-A-Stats\"\n",
    "tabela_df = tabela_brasileirao(tabela_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_df.drop(['Attendance', 'Top Team Scorer', 'Goalkeeper', 'Notes'], axis= 'columns', inplace= True)\n",
    "tabela_df['xGConv'] = tabela_df['GF'] - tabela_df['xG']   #Conversão de xG\n",
    "tabela_df['xGAConv'] = tabela_df['GA'] - tabela_df['xGA']   #Conversão de xGA\n",
    "tabela_df['GF/MP'] = tabela_df['GF']/tabela_df['MP']    #Gols feitos por partida jogada\n",
    "tabela_df['GA/MP'] = tabela_df['GA']/tabela_df['MP']    #Gols recebidos por partida jogada\n",
    "tabela_df['Squad'] = tabela_df['Squad'].apply(remover_acentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerar planilha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodada = tabela_df['MP'].max()\n",
    "tabela_df.to_excel(f'dados/tabela/rodada-{rodada}.xlsx', sheet_name='tabela', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historico por time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodada = tabela['MP'].max()\n",
    "if not os.path.exists(f'dados/historico/times/rodada_{rodada}'):\n",
    "  os.makedirs(f'dados/historico/times/rodada_{rodada}')\n",
    "\n",
    "for time in historico_casa['Equipe']:\n",
    "  df = historico_casa[historico_casa['Equipe'] == time]\n",
    "  df = pd.concat([df, historico_casa[historico_casa['Opponent'] == time]])\n",
    "  df.to_excel(f'dados/historico/times/rodada_{rodada}/{time}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximas Rodadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxs_rodadas(tabela_url):\n",
    "  data = requests.get(tabela_url)\n",
    "  tabela = pd.read_html(data.text, match= 'Scores & Fixtures')[0]\n",
    "  return tabela\n",
    "\n",
    "rodadas_url = \"https://fbref.com/en/comps/24/schedule/Serie-A-Scores-and-Fixtures\"\n",
    "rodadas_df = proxs_rodadas(rodadas_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodadas_df = rodadas_df.loc[rodadas_df['Home'] != 'nan']\n",
    "rodadas_df = rodadas_df.loc[rodadas_df['Away'] != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mg:\\Meu Drive\\Bet\\get_data.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Meu%20Drive/Bet/get_data.ipynb#X30sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     rodadas_df[\u001b[39m'\u001b[39m\u001b[39mAway\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m rodadas_df[\u001b[39m'\u001b[39m\u001b[39mAway\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(unidecode(key), value, regex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Meu%20Drive/Bet/get_data.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#rodadas_df.drop(['Time', 'Attendance', 'Venue', 'Referee', 'Match Report', 'Notes'], axis= 1, inplace= True)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/Meu%20Drive/Bet/get_data.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m rodadas_df[[\u001b[39m'\u001b[39m\u001b[39mgols_casa\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgols_fora\u001b[39m\u001b[39m'\u001b[39m]] \u001b[39m=\u001b[39m rodadas_df[\u001b[39m'\u001b[39;49m\u001b[39mScore\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m–\u001b[39m\u001b[39m'\u001b[39m, expand\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Meu%20Drive/Bet/get_data.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#rodadas_df.drop(['Score'], axis= 1, inplace= True)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/Meu%20Drive/Bet/get_data.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m rodadas_df\u001b[39m.\u001b[39minsert(\u001b[39m5\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgols_casa\u001b[39m\u001b[39m'\u001b[39m, rodadas_df\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mgols_casa\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Score'"
     ]
    }
   ],
   "source": [
    "rodadas_df['Home'] = rodadas_df['Home'].apply(remover_acentos)\n",
    "rodadas_df['Away'] = rodadas_df['Away'].apply(remover_acentos)\n",
    "\n",
    "substitutions = {\n",
    "    'Botafogo-RJ': 'Botafogo (RJ)',\n",
    "    'Gremio': 'Gremio',\n",
    "    'Athletico-Paranaense': 'Ath Paranaense',\n",
    "    'Atletico-Mineiro': 'Atletico Mineiro',\n",
    "    'Sao-Paulo': 'Sao Paulo',\n",
    "    'Vasco-da-Gama': 'Vasco da Gama',\n",
    "    'America-MG': 'America (MG)'\n",
    "}\n",
    "\n",
    "for key, value in substitutions.items():\n",
    "    rodadas_df['Home'] = rodadas_df['Home'].str.replace(unidecode(key), value, regex=True)\n",
    "    rodadas_df['Away'] = rodadas_df['Away'].str.replace(unidecode(key), value, regex=True)\n",
    "\n",
    "rodadas_df.drop(['Time', 'Attendance', 'Venue', 'Referee', 'Match Report', 'Notes'], axis= 1, inplace= True)\n",
    "rodadas_df[['gols_casa', 'gols_fora']] = rodadas_df['Score'].str.split('–', expand=True)\n",
    "rodadas_df.drop(['Score'], axis= 1, inplace= True)\n",
    "rodadas_df.insert(5, 'gols_casa', rodadas_df.pop('gols_casa'))\n",
    "rodadas_df.insert(6, 'gols_fora', rodadas_df.pop('gols_fora'))\n",
    "rodadas_df = rodadas_df.rename(columns={'xG.1': 'xGFora', 'xG': 'xGCasa'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(value):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return pd.NA\n",
    "    \n",
    "rodadas_df['gols_casa'] = rodadas_df['gols_casa'].apply(convert_to_int)\n",
    "rodadas_df['gols_fora'] = rodadas_df['gols_fora'].apply(convert_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rodadas_df.to_excel(f'dados/previsoes/rodadas.xlsx', sheet_name='tabela', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
